/**
 * ğŸ¤– OpenAI Service
 * 
 * AI ê¸°ë°˜ ê¸°ëŠ¥
 * - í‘œì¤€ ê²¬ì  ìë™ ìƒì„±
 * - í”„ë¡œì íŠ¸ ë¶„ì„
 * - AI PM ë³´ì¡° ì‹œìŠ¤í…œ
 * 
 * @see https://platform.openai.com/docs/api-reference
 */

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface OpenAIRequest {
  model: string;
  messages: ChatMessage[];
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
}

export interface OpenAIResponse {
  success: boolean;
  data?: {
    id: string;
    choices: Array<{
      message: {
        role: string;
        content: string;
      };
      finish_reason: string;
    }>;
    usage: {
      prompt_tokens: number;
      completion_tokens: number;
      total_tokens: number;
    };
  };
  error?: string;
}

/**
 * OpenAI API í˜¸ì¶œ
 */
export async function chat(
  apiKey: string,
  request: OpenAIRequest
): Promise<OpenAIResponse> {
  try {
    // í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if (apiKey.includes('test_key')) {
      console.log('ğŸ¤– [DEV MODE] AI request:', {
        model: request.model,
        messages: request.messages.map(m => ({ role: m.role, preview: m.content.substring(0, 50) }))
      });
      
      return {
        success: true,
        data: {
          id: 'chatcmpl-test-' + Date.now(),
          choices: [{
            message: {
              role: 'assistant',
              content: '[í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ AI ì‘ë‹µì´ í‘œì‹œë©ë‹ˆë‹¤.'
            },
            finish_reason: 'stop'
          }],
          usage: {
            prompt_tokens: 100,
            completion_tokens: 50,
            total_tokens: 150
          }
        }
      };
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(request)
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`OpenAI API error: ${error}`);
    }

    const data = await response.json();
    return {
      success: true,
      data
    };
  } catch (error) {
    console.error('Failed to call OpenAI:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    };
  }
}

/**
 * í”„ë¡œì íŠ¸ ê²¬ì  ìë™ ìƒì„±
 */
export async function generateProjectEstimate(
  apiKey: string,
  projectDescription: string,
  requirements: string[],
  language: 'ko' | 'en' | 'zh' | 'ja' = 'ko'
): Promise<OpenAIResponse> {
  const systemPrompts = {
    ko: `ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ê²¬ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
í”„ë¡œì íŠ¸ ì„¤ëª…ê³¼ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ê¸°ëŠ¥ ë¶„í•´** (ì£¼ìš” ê¸°ëŠ¥ì„ ì„¸ë¶€ ì‘ì—…ìœ¼ë¡œ ë¶„í•´)
2. **ë‚œì´ë„ ì ìˆ˜** (ê° ê¸°ëŠ¥ë³„ 1-10ì , ì´ìœ  í¬í•¨)
3. **ì˜ˆìƒ ì‘ì—… ì‹œê°„** (ê° ê¸°ëŠ¥ë³„ ì‹œê°„, ì´ ì‹œê°„)
4. **ê¶Œì¥ ì˜ˆì‚° ë²”ìœ„** (ìµœì†Œ-ìµœëŒ€ USD)
5. **ìœ„í—˜ ìš”ì†Œ** (í”„ë¡œì íŠ¸ ì§„í–‰ ì‹œ ì£¼ì˜í•  ì )
6. **ê¶Œì¥ ê¸°ìˆ  ìŠ¤íƒ**

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.`,
    en: `You are an IT project estimation expert.
Analyze the project description and requirements, then provide:

1. **Feature Breakdown** (Decompose main features into subtasks)
2. **Difficulty Score** (1-10 for each feature with reasons)
3. **Estimated Hours** (Per feature and total)
4. **Budget Range** (Min-Max in USD)
5. **Risk Factors** (Project concerns)
6. **Recommended Tech Stack**

Respond in JSON format.`,
    zh: `ä½ æ˜¯ä¸€ä½ITé¡¹ç›®è¯„ä¼°ä¸“å®¶ã€‚
åˆ†æé¡¹ç›®æè¿°å’Œéœ€æ±‚ï¼Œç„¶åæä¾›ï¼š

1. **åŠŸèƒ½åˆ†è§£**ï¼ˆå°†ä¸»è¦åŠŸèƒ½åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼‰
2. **éš¾åº¦è¯„åˆ†**ï¼ˆæ¯ä¸ªåŠŸèƒ½1-10åˆ†ï¼ŒåŒ…å«ç†ç”±ï¼‰
3. **é¢„ä¼°å·¥æ—¶**ï¼ˆæ¯ä¸ªåŠŸèƒ½å’Œæ€»å·¥æ—¶ï¼‰
4. **é¢„ç®—èŒƒå›´**ï¼ˆæœ€å°-æœ€å¤§USDï¼‰
5. **é£é™©å› ç´ **ï¼ˆé¡¹ç›®æ³¨æ„äº‹é¡¹ï¼‰
6. **æ¨èæŠ€æœ¯æ ˆ**

ä»¥JSONæ ¼å¼å›ç­”ã€‚`,
    ja: `ã‚ãªãŸã¯ITãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¦‹ç©ã‚‚ã‚Šå°‚é–€å®¶ã§ã™ã€‚
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èª¬æ˜ã¨è¦ä»¶ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

1. **æ©Ÿèƒ½åˆ†è§£**ï¼ˆä¸»è¦æ©Ÿèƒ½ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ï¼‰
2. **é›£æ˜“åº¦ã‚¹ã‚³ã‚¢**ï¼ˆå„æ©Ÿèƒ½1-10ç‚¹ã€ç†ç”±ã‚’å«ã‚€ï¼‰
3. **æ¨å®šå·¥æ•°**ï¼ˆæ©Ÿèƒ½ã”ã¨ã¨åˆè¨ˆï¼‰
4. **äºˆç®—ç¯„å›²**ï¼ˆæœ€å°-æœ€å¤§USDï¼‰
5. **ãƒªã‚¹ã‚¯è¦å› **ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ³¨æ„ç‚¹ï¼‰
6. **æ¨å¥¨æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚`
  };

  return await chat(apiKey, {
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: systemPrompts[language]
      },
      {
        role: 'user',
        content: `í”„ë¡œì íŠ¸ ì„¤ëª…: ${projectDescription}\n\nìš”êµ¬ì‚¬í•­:\n${requirements.map((r, i) => `${i + 1}. ${r}`).join('\n')}`
      }
    ],
    temperature: 0.7,
    max_tokens: 2000
  });
}

/**
 * AI PM ë³´ì¡° - ì¼ì • ì§€ì—° ë¶„ì„
 */
export async function analyzeProjectDelay(
  apiKey: string,
  projectTitle: string,
  originalDeadline: string,
  currentProgress: number,
  remainingDays: number,
  language: 'ko' | 'en' | 'zh' | 'ja' = 'ko'
): Promise<OpenAIResponse> {
  const prompts = {
    ko: `í”„ë¡œì íŠ¸ ì¼ì • ì§€ì—° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

í”„ë¡œì íŠ¸: ${projectTitle}
ì›ë˜ ë§ˆê°ì¼: ${originalDeadline}
í˜„ì¬ ì§„í–‰ë¥ : ${currentProgress}%
ë‚¨ì€ ê¸°ê°„: ${remainingDays}ì¼

ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. risk_level: "low" | "medium" | "high"
2. completion_probability: 0-100 (%)
3. recommendations: ë°°ì—´ (ê°œì„  ë°©ì•ˆ)
4. estimated_extra_days: ì¶”ê°€ í•„ìš” ì¼ìˆ˜
5. summary: ì „ì²´ ìš”ì•½`,
    en: `Analyze project delay.

Project: ${projectTitle}
Original Deadline: ${originalDeadline}
Current Progress: ${currentProgress}%
Days Remaining: ${remainingDays}

Provide in JSON:
1. risk_level: "low" | "medium" | "high"
2. completion_probability: 0-100 (%)
3. recommendations: array
4. estimated_extra_days: number
5. summary: string`,
    zh: `åˆ†æé¡¹ç›®å»¶æœŸã€‚

é¡¹ç›®ï¼š${projectTitle}
åŸå®šæˆªæ­¢æ—¥æœŸï¼š${originalDeadline}
å½“å‰è¿›åº¦ï¼š${currentProgress}%
å‰©ä½™å¤©æ•°ï¼š${remainingDays}

ä»¥JSONæ ¼å¼æä¾›ï¼š
1. risk_level: "low" | "medium" | "high"
2. completion_probability: 0-100 (%)
3. recommendations: æ•°ç»„
4. estimated_extra_days: æ•°å­—
5. summary: å­—ç¬¦ä¸²`,
    ja: `ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é…å»¶åˆ†æã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼š${projectTitle}
å…ƒã®ç· åˆ‡ï¼š${originalDeadline}
ç¾åœ¨ã®é€²æ—ï¼š${currentProgress}%
æ®‹ã‚Šæ—¥æ•°ï¼š${remainingDays}

JSONå½¢å¼ã§æä¾›ï¼š
1. risk_level: "low" | "medium" | "high"
2. completion_probability: 0-100 (%)
3. recommendations: é…åˆ—
4. estimated_extra_days: æ•°å€¤
5. summary: æ–‡å­—åˆ—`
  };

  return await chat(apiKey, {
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: 'You are an AI project manager assistant. Analyze delays and provide actionable insights.'
      },
      {
        role: 'user',
        content: prompts[language]
      }
    ],
    temperature: 0.3,
    max_tokens: 1000
  });
}

/**
 * ìš”êµ¬ì‚¬í•­ ëª…í™•í™” ë„ìš°ë¯¸
 */
export async function clarifyRequirements(
  apiKey: string,
  userRequirement: string,
  language: 'ko' | 'en' | 'zh' | 'ja' = 'ko'
): Promise<OpenAIResponse> {
  const systemPrompts = {
    ko: 'ì‚¬ìš©ìì˜ ëª¨í˜¸í•œ ìš”êµ¬ì‚¬í•­ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”. êµ¬ì²´ì ì¸ ì§ˆë¬¸ 3-5ê°œì™€ ê¶Œì¥ ê¸°ëŠ¥ ëª…ì„¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.',
    en: 'Clarify vague requirements. Provide 3-5 specific questions and recommended feature specs.',
    zh: 'æ¾„æ¸…æ¨¡ç³Šçš„éœ€æ±‚ã€‚æä¾›3-5ä¸ªå…·ä½“é—®é¢˜å’Œæ¨èçš„åŠŸèƒ½è§„æ ¼ã€‚',
    ja: 'æ›–æ˜§ãªè¦ä»¶ã‚’æ˜ç¢ºã«ã—ã¦ãã ã•ã„ã€‚3-5ã¤ã®å…·ä½“çš„ãªè³ªå•ã¨æ¨å¥¨æ©Ÿèƒ½ä»•æ§˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚'
  };

  return await chat(apiKey, {
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: systemPrompts[language]
      },
      {
        role: 'user',
        content: userRequirement
      }
    ],
    temperature: 0.5,
    max_tokens: 1500
  });
}

/**
 * ì½”ë“œ ë¦¬ë·° ë„ìš°ë¯¸
 */
export async function reviewCode(
  apiKey: string,
  code: string,
  language: 'javascript' | 'typescript' | 'python' | 'java' | 'go',
  reviewLanguage: 'ko' | 'en' | 'zh' | 'ja' = 'ko'
): Promise<OpenAIResponse> {
  const prompts = {
    ko: `ë‹¤ìŒ ${language} ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:

\`\`\`${language}
${code}
\`\`\`

ë‹¤ìŒì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. quality_score: 1-10
2. issues: ë°°ì—´ (ë¬¸ì œì )
3. suggestions: ë°°ì—´ (ê°œì„  ì œì•ˆ)
4. security_concerns: ë°°ì—´ (ë³´ì•ˆ ì´ìŠˆ)
5. performance_tips: ë°°ì—´ (ì„±ëŠ¥ ê°œì„ )`,
    en: `Review this ${language} code:

\`\`\`${language}
${code}
\`\`\`

Provide in JSON:
1. quality_score: 1-10
2. issues: array
3. suggestions: array
4. security_concerns: array
5. performance_tips: array`,
    zh: `å®¡æŸ¥è¿™æ®µ${language}ä»£ç ï¼š

\`\`\`${language}
${code}
\`\`\`

ä»¥JSONæ ¼å¼æä¾›ï¼š
1. quality_score: 1-10
2. issues: æ•°ç»„
3. suggestions: æ•°ç»„
4. security_concerns: æ•°ç»„
5. performance_tips: æ•°ç»„`,
    ja: `ã“ã®${language}ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ï¼š

\`\`\`${language}
${code}
\`\`\`

JSONå½¢å¼ã§æä¾›ï¼š
1. quality_score: 1-10
2. issues: é…åˆ—
3. suggestions: é…åˆ—
4. security_concerns: é…åˆ—
5. performance_tips: é…åˆ—`
  };

  return await chat(apiKey, {
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: 'You are a senior code reviewer. Provide constructive feedback on code quality, security, and performance.'
      },
      {
        role: 'user',
        content: prompts[reviewLanguage]
      }
    ],
    temperature: 0.3,
    max_tokens: 2000
  });
}
